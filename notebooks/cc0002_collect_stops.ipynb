{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "according-jungle",
   "metadata": {},
   "source": [
    "# Collect Stops\n",
    "\n",
    "#### Primary Author\n",
    "Chris Carey\n",
    "\n",
    "#### Description:\n",
    "This notebook collects all Citi Bike station locations along with reported dates.\n",
    "\n",
    "#### Inputs:\n",
    "```\n",
    "data/citibike/date_prefixes.npy\n",
    "```\n",
    " \n",
    "#### Outputs:\n",
    "```\n",
    "data/citibike/csv/exports/station_coords.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "binary-second",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "racial-computer",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data'\n",
    "CITIBIKE_CSV_DIR = f'{DATA_DIR}/citibike/csv'\n",
    "EXPORTS_DIR = f'{DATA_DIR}/citibike/exports'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "instrumental-break",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE_PREFIXES = np.load(f'{DATA_DIR}/citibike/date_prefixes.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "significant-boutique",
   "metadata": {},
   "outputs": [],
   "source": [
    "def peek(df):\n",
    "    display(df.iloc[:3])\n",
    "    print(len(df))\n",
    "    \n",
    "def hash_station_id(station_id):\n",
    "    try:\n",
    "        float_id = float(station_id)\n",
    "        int_id = int(float(station_id))\n",
    "        if int_id == float_id:\n",
    "            return str(int_id)\n",
    "        else:\n",
    "            return str(float_id)\n",
    "    except:\n",
    "        return str(station_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-pennsylvania",
   "metadata": {},
   "source": [
    "## Collect Citi Bike Stops with Monthly Granularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "subject-industry",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_dict = {}\n",
    "def add_row_to_station_dict(row):\n",
    "    (station_id, lat, lon) = tuple(row[1])\n",
    "    station_id = hash_station_id(station_id)\n",
    "    if station_id not in station_dict:\n",
    "        station_dict[station_id] = {}\n",
    "    if (lat, lon) not in station_dict[station_id]:\n",
    "        station_dict[station_id][(lat, lon)] = date_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "original-shelter",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [08:58<00:00,  5.55s/it]\n"
     ]
    }
   ],
   "source": [
    "trip_dfs = []\n",
    "\n",
    "for date_prefix in tqdm(DATE_PREFIXES):\n",
    "    df = pd.read_csv(f'{CITIBIKE_CSV_DIR}/{date_prefix}-citibike-tripdata.csv')\n",
    "    df = df.rename(columns={\n",
    "        'Bike ID': 'bike_id',\n",
    "        'Birth Year': 'birth_year',\n",
    "        'End Station ID': 'end_station_id',\n",
    "        'End Station Latitude': 'end_lat',\n",
    "        'End Station Longitude': 'end_lon',\n",
    "        'End Station Name': 'end_station_name',\n",
    "        'Gender': 'gender',\n",
    "        'Start Station ID': 'start_station_id',\n",
    "        'Start Station Latitude': 'start_lat',\n",
    "        'Start Station Longitude': 'start_lon',\n",
    "        'Start Station Name': 'start_station_name',\n",
    "        'Start Time': 'start_time',\n",
    "        'Stop Time': 'stop_time',\n",
    "        'User Type': 'user_type',\n",
    "        'Trip Duration': 'trip_duration',\n",
    "        'bikeid': 'bike_id',\n",
    "        'birth year': 'birth_year',\n",
    "        'end station id': 'end_station_id',\n",
    "        'end station latitude': 'end_lat',\n",
    "        'end station longitude': 'end_lon',\n",
    "        'end station name': 'end_station_name',\n",
    "        'end_lng': 'end_lon',\n",
    "        'start station id': 'start_station_id',\n",
    "        'start station latitude': 'start_lat',\n",
    "        'start station longitude': 'start_lon',\n",
    "        'start station name': 'start_station_name',\n",
    "        'start_lng': 'start_lon',\n",
    "        'started_at': 'start_time',\n",
    "        'starttime': 'start_time',\n",
    "        'stoptime': 'stop_time',\n",
    "        'tripduration': 'trip_duration',\n",
    "        'usertype': 'user_type',\n",
    "    })\n",
    "    trip_dfs.append(df)\n",
    "    \n",
    "    start_df = df[['start_station_id', 'start_lat', 'start_lon']].drop_duplicates()\n",
    "    end_df = df[['end_station_id', 'end_lat', 'end_lon']].drop_duplicates()\n",
    "\n",
    "    for row in start_df.iterrows():\n",
    "        add_row_to_station_dict(row)\n",
    "    for row in end_df.iterrows():\n",
    "        add_row_to_station_dict(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "composed-assembly",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {'id': [], 'date': [], 'lat': [], 'lon': []}\n",
    "for station_id, pos_dict in station_dict.items():\n",
    "    for pos, date in pos_dict.items():\n",
    "        df_dict['id'].append(station_id)\n",
    "        df_dict['lat'].append(pos[0])\n",
    "        df_dict['lon'].append(pos[1])\n",
    "        df_dict['date'].append(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earlier-resistance",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_df = pd.DataFrame(df_dict)\n",
    "station_df = station_df.sort_values(by=['id', 'date'])\n",
    "station_df = station_df[station_df['id'] != 'nan']\n",
    "station_df = station_df.dropna()\n",
    "station_df = station_df.reset_index(drop=True)\n",
    "station_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-cargo",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_df.to_csv(f'{EXPORTS_DIR}/station_coords.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-regulation",
   "metadata": {},
   "source": [
    "## Collect Citi Bike Stops with Perfect Granularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "atmospheric-posting",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_dict = {}\n",
    "station_df = pd.DataFrame({'id': [], 'date': [], 'lat': [], 'lon': []})\n",
    "\n",
    "def add_row_to_station_dict(row):\n",
    "    (station_id, lat, lon) = tuple(row[1])\n",
    "    station_id = hash_station_id(station_id)\n",
    "    if station_id not in station_dict:\n",
    "        station_dict[station_id] = {}\n",
    "    if (lat, lon) not in station_dict[station_id]:\n",
    "        station_dict[station_id] = (lat, lon)\n",
    "        station_df.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "selective-updating",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:26<00:00,  3.67it/s]\n"
     ]
    }
   ],
   "source": [
    "station_dfs = []\n",
    "\n",
    "for df in tqdm(trip_dfs):\n",
    "    start_df = df.groupby(by=['start_station_id', 'start_lat', 'start_lon']).agg({'start_time': 'first'}).reset_index()\n",
    "    end_df = df.groupby(by=['end_station_id', 'end_lat', 'end_lon']).agg({'start_time': 'first'}).reset_index()\n",
    "    \n",
    "    start_df = start_df.rename(columns={\n",
    "        'start_station_id': 'id',\n",
    "        'start_lat': 'lat',\n",
    "        'start_lon': 'lon',\n",
    "        'start_time': 'date',\n",
    "    })\n",
    "    end_df = end_df.rename(columns={\n",
    "        'end_station_id': 'id',\n",
    "        'end_lat': 'lat',\n",
    "        'end_lon': 'lon',\n",
    "        'start_time': 'date',\n",
    "    })\n",
    "    \n",
    "    all_df = pd.concat([start_df, end_df])[['id', 'lat', 'lon', 'date']]\n",
    "    all_df = all_df.groupby(by=['id', 'lat', 'lon']).agg({'date': 'first'}).reset_index()\n",
    "    station_dfs.append(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "driven-insulin",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_df = pd.concat(station_dfs)\n",
    "stations_df['date'] = pd.to_datetime(stations_df['date'])\n",
    "stations_df = stations_df.sort_values(by=['date'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "downtown-bidder",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_df = stations_df.groupby(by=['id', 'lat', 'lon']).agg({'date': 'first'}).reset_index()\n",
    "stations_df = stations_df.sort_values(by=['date'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "simplified-doctor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72</td>\n",
       "      <td>40.767000</td>\n",
       "      <td>-73.995000</td>\n",
       "      <td>2020-03-10 21:23:55.618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72</td>\n",
       "      <td>40.767272</td>\n",
       "      <td>-73.993929</td>\n",
       "      <td>2013-10-01 00:40:09.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79</td>\n",
       "      <td>40.719000</td>\n",
       "      <td>-74.007000</td>\n",
       "      <td>2020-02-21 19:47:27.787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79</td>\n",
       "      <td>40.719116</td>\n",
       "      <td>-74.006667</td>\n",
       "      <td>2013-10-01 00:17:44.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82</td>\n",
       "      <td>40.710000</td>\n",
       "      <td>-74.001000</td>\n",
       "      <td>2020-03-05 18:01:06.295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7658</th>\n",
       "      <td>SYS033</td>\n",
       "      <td>40.728487</td>\n",
       "      <td>-74.011693</td>\n",
       "      <td>2021-02-05 10:11:47.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7659</th>\n",
       "      <td>SYS035</td>\n",
       "      <td>40.728660</td>\n",
       "      <td>-74.011980</td>\n",
       "      <td>2021-02-27 14:22:51.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7660</th>\n",
       "      <td>SYS035</td>\n",
       "      <td>40.728660</td>\n",
       "      <td>-74.011980</td>\n",
       "      <td>2021-02-17 15:04:43.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7661</th>\n",
       "      <td>SYS037</td>\n",
       "      <td>40.716878</td>\n",
       "      <td>-73.983755</td>\n",
       "      <td>2021-07-24 15:03:38.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7662</th>\n",
       "      <td>SYS038</td>\n",
       "      <td>40.709306</td>\n",
       "      <td>-73.931175</td>\n",
       "      <td>2021-10-14 10:34:03.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7663 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id        lat        lon                    date\n",
       "0         72  40.767000 -73.995000 2020-03-10 21:23:55.618\n",
       "1         72  40.767272 -73.993929 2013-10-01 00:40:09.000\n",
       "2         79  40.719000 -74.007000 2020-02-21 19:47:27.787\n",
       "3         79  40.719116 -74.006667 2013-10-01 00:17:44.000\n",
       "4         82  40.710000 -74.001000 2020-03-05 18:01:06.295\n",
       "...      ...        ...        ...                     ...\n",
       "7658  SYS033  40.728487 -74.011693 2021-02-05 10:11:47.000\n",
       "7659  SYS035  40.728660 -74.011980 2021-02-27 14:22:51.000\n",
       "7660  SYS035  40.728660 -74.011980 2021-02-17 15:04:43.000\n",
       "7661  SYS037  40.716878 -73.983755 2021-07-24 15:03:38.000\n",
       "7662  SYS038  40.709306 -73.931175 2021-10-14 10:34:03.000\n",
       "\n",
       "[7663 rows x 4 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-publication",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
